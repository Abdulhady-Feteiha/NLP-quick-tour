{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP interview.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNjg9VX0xjkZO8MhX//CNBV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdulhady-Feteiha/NLP-quick-tour-/blob/main/NLP_quick_tour.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gSQyohO2qHqv"
      },
      "outputs": [],
      "source": [
        "#imports \n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## You know, some donwloads"
      ],
      "metadata": {
        "id": "Tv0AD0Uh4gw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "!python -m spacy download en_core_web_md "
      ],
      "metadata": {
        "id": "O2TqV0tgviA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokeniaztion | nltk\n"
      ],
      "metadata": {
        "id": "sp-_kzHbqmfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "The_words_of_god = \"Hey there, smile. the univers is smiling back.\"\n",
        "sent_Tokenized = sent_tokenize(The_words_of_god)\n",
        "word_Tokenized = word_tokenize(The_words_of_god)\n",
        "\n",
        "print('sent_tokenize: ',sent_Tokenized)\n",
        "print('word_Tokenized: ',word_Tokenized)"
      ],
      "metadata": {
        "id": "x5B4qKhgqhfl",
        "outputId": "58d3e762-d780-4f98-a704-8c576d199354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sent_tokenize:  ['Hey there, smile.', 'the univers is smiling back.']\n",
            "word_Tokenized:  ['Hey', 'there', ',', 'smile', '.', 'the', 'univers', 'is', 'smiling', 'back', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-grams | nltk"
      ],
      "metadata": {
        "id": "uZq-5ocWqvMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  n = 4\n",
        "  print(list(nltk.ngrams(word_Tokenized,n)))"
      ],
      "metadata": {
        "id": "5lE_0nf8qtBS",
        "outputId": "1088a0a2-6fdd-4155-b9ac-4ebbe5ed4acd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Hey', 'there', ',', 'smile'), ('there', ',', 'smile', '.'), (',', 'smile', '.', 'the'), ('smile', '.', 'the', 'univers'), ('.', 'the', 'univers', 'is'), ('the', 'univers', 'is', 'smiling'), ('univers', 'is', 'smiling', 'back'), ('is', 'smiling', 'back', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming | nltk"
      ],
      "metadata": {
        "id": "FjboIDBRq1FL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pst=PorterStemmer()\n",
        "for token in word_Tokenized:\n",
        "  print(pst.stem(token))"
      ],
      "metadata": {
        "id": "CduuiNrkq2xT",
        "outputId": "245a51ec-bdd1-4c86-c9a4-ed7258ab14fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hey\n",
            "there\n",
            ",\n",
            "smile\n",
            ".\n",
            "the\n",
            "univ\n",
            "is\n",
            "smile\n",
            "back\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatization | nltk"
      ],
      "metadata": {
        "id": "OhOIuO9Etqe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemma= WordNetLemmatizer()\n",
        "for token in word_Tokenized:\n",
        "  print(token + \":\" + lemma.lemmatize(token))"
      ],
      "metadata": {
        "id": "sOSdyqdSsCBe",
        "outputId": "1deb2deb-0bcb-484f-9ebf-05ff87e51601",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hey:Hey\n",
            "there:there\n",
            ",:,\n",
            "smile:smile\n",
            ".:.\n",
            "the:the\n",
            "univers:univers\n",
            "is:is\n",
            "smiling:smiling\n",
            "back:back\n",
            ".:.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## POS | nltk"
      ],
      "metadata": {
        "id": "RUmnw4c6u6eW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "txt = \"Sourav, Pratyush, and Abhinav are good friends.\"  \n",
        "\n",
        "wordsList = [w for w in word_Tokenized if not w in stop_words]\n",
        "print(\"Stop words removed:\")\n",
        "print(wordsList)\n",
        "print(\"POS:\")\n",
        "tagged_words = nltk.pos_tag(wordsList)\n",
        "print(tagged_words)"
      ],
      "metadata": {
        "id": "6PP-iEoUuF2u",
        "outputId": "1573e1ac-5b69-45d7-e1f3-4a9a858c56b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop words removed:\n",
            "['Hey', ',', 'smile', '.', 'univers', 'smiling', 'back', '.']\n",
            "POS:\n",
            "[('Hey', 'NNP'), (',', ','), ('smile', 'NN'), ('.', '.'), ('univers', 'NNS'), ('smiling', 'VBG'), ('back', 'RB'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NER | SpaCy"
      ],
      "metadata": {
        "id": "9Y9VR88xxCN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "NER = spacy.load(\"en_core_web_sm\")\n",
        "raw_text=\"I enjoy so much free diving in Dahab, Egypt. It all started 2 years ago when i first felt a mamlian reflex effect while under water that hooked me to the hobby.\"\n",
        "text1= NER(raw_text)\n",
        "print(\"NER output:\")\n",
        "for word in text1.ents:\n",
        "    print(word.text,word.label_)\n",
        "print(\"What is an ORG? \\n\",spacy.explain(\"ORG\"))\n"
      ],
      "metadata": {
        "id": "9h6ZxKorvXEf",
        "outputId": "f4fa95b4-e211-4faa-a507-2ddc271b889b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NER output:\n",
            "Dahab GPE\n",
            "Egypt GPE\n",
            "2 years ago DATE\n",
            "first ORDINAL\n",
            "mamlian NORP\n",
            "What is an ORG? \n",
            " Companies, agencies, institutions, etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(text1,style=\"ent\",jupyter=True)"
      ],
      "metadata": {
        "id": "lNoVQriLwRxk",
        "outputId": "1bdf3763-068b-4155-8b42-3eba68f7d72c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I enjoy so much free diving in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Dahab\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Egypt\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ". It all started \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2 years ago\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " when i \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    first\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " felt a \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    mamlian\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " reflex effect while under water that hooked me to the hobby.</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similarity | SpaCy\n"
      ],
      "metadata": {
        "id": "M4t7adnmy_cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "Sentence1 = nlp('The ancient Egyptian civilization were the first to disover the color blue')\n",
        "Sentence2 = nlp('The pharoas discovered the color blue first')\n",
        "Sentence3 = nlp('Blue describes a shade of wavelengths ragning around 6.66x10^14 Hz')\n",
        "Sentence4 = nlp('Dogs are cute man!')\n",
        "print(\"Two similar sentences:\", Sentence1.similarity(Sentence2))\n",
        "print(\"Two simi similar sentences:\", Sentence1.similarity(Sentence3))\n",
        "print(\"Two non similar sentences:\", Sentence1.similarity(Sentence4))"
      ],
      "metadata": {
        "id": "zo1GcP7ny1iy",
        "outputId": "bc2ea8f3-e8d0-416d-c6b6-eafe576e6fcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Two similar sentences: 0.8835315773093688\n",
            "Two simi similar sentences: 0.6293763995810023\n",
            "Two non similar sentences: 0.19793447908323122\n"
          ]
        }
      ]
    }
  ]
}